import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
# Adicionamos AIMessage para representar a fala da IA
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

load_dotenv()

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.3)

# --- CONFIGURA√á√ÉO DA MEM√ìRIA ---
# A lista come√ßa com a personalidade do bot
historico_conversa = [
    SystemMessage(content="Voc√™ √© um assistente s√™nior em programa√ß√£o. Ajude com respostas diretas e exemplos de c√≥digo.")
]

def conversar():
    print("--- Chatbot com Mem√≥ria Iniciado (Digite 'sair' para encerrar) ---")
    
    while True:
        texto_usuario = input("\nVoc√™: ")
        if texto_usuario.lower() == 'sair':
            break
        
        # 1. Adiciona o que voc√™ disse ao hist√≥rico
        historico_conversa.append(HumanMessage(content=texto_usuario))
        
        print("ü§ñ ...")
        
        # 2. Envia O HIST√ìRICO INTEIRO para a IA, n√£o apenas a √∫ltima frase
        resposta_ai = llm.invoke(historico_conversa)
        
        # 3. Mostra a resposta
        print(f"Bot: {resposta_ai.content}")
        
        # 4. Salva a resposta da IA no hist√≥rico tamb√©m (para ela lembrar o que ela mesma disse)
        historico_conversa.append(AIMessage(content=resposta_ai.content))

if __name__ == "__main__":
    conversar()